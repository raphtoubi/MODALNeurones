{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "import os as os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def convertLabel(sequence): #gives a nb to the aminoacid\n",
    "    label = sequence[7]\n",
    "    aminoacidList = [\"ALA\", \"ARG\", \"ASN\", \"ASP\", \"CYS\", \"GLU\", \"GLN\", \"GLY\", \"HIS\", \"ILE\",\n",
    "                    \"LEU\", \"LYS\", \"MET\", \"PHE\", \"PRO\", \"PYL\", \"SEL\", \"SER\", \"THR\", \"TRP\", \"TYR\", \"VAL\"]\n",
    "    for i in range (0, 22):\n",
    "        if label == aminoacidList[i]:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filename = \"matrices1.csv\"\n",
    "def load_data():\n",
    "\n",
    "\n",
    "    labelList = []\n",
    "\n",
    "    with open(filename) as f:\n",
    "\n",
    "        nbOfSamples = int(f.readline())\n",
    "        i = 0\n",
    "\n",
    "        shapes = f.readline() # length of sequence + nb of features\n",
    "        input_shape = int(shapes.split(\",\")[1])\n",
    "\n",
    "\n",
    "        distancesList = np.zeros((nbOfSamples, input_shape))\n",
    "        labelList = np.zeros(nbOfSamples)\n",
    "\n",
    "\n",
    "        while i < nbOfSamples:\n",
    "            # Extracting labels\n",
    "            sequence = f.readline().split(\",\")\n",
    "            labelList[i] = convertLabel(sequence)\n",
    "\n",
    "            # Extracting distances\n",
    "            distancesString = f.readline()\n",
    "            distancesArray = np.array([float(s) for s in distancesString.split(\",\")])\n",
    "            distancesList[i, :] = distancesArray\n",
    "\n",
    "            # empty line\n",
    "            f.readline()\n",
    "\n",
    "            i += 1\n",
    "    return input_shape, distancesList, labelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    # activation function: leaky ReLU\n",
    "    leakyrelu = lambda x: tf.keras.activations.relu(x, alpha=0.01, max_value=None, threshold=0)\n",
    "\n",
    "    # creation du reseau de neurones\n",
    "    model = tf.keras.models.Sequential([\n",
    "\n",
    "        # hidden layer\n",
    "        tf.keras.layers.Dense(units = 105, activation = leakyrelu, input_shape = (105,)),\n",
    "      #  keras.layers.Dropout(rate=0.2),\n",
    "        tf.keras.layers.Dense(units = 210, activation = leakyrelu),\n",
    "       # keras.layers.Dropout(rate=0.2),\n",
    "        tf.keras.layers.Dense(units = 210, activation = leakyrelu),\n",
    "        #keras.layers.Dropout(rate=0.2),\n",
    "        tf.keras.layers.Dense(units = 210, activation = leakyrelu),\n",
    "        tf.keras.layers.Dense(units = 100, activation = leakyrelu),\n",
    "        #keras.layers.Dropout(rate=0.2),\n",
    "        tf.keras.layers.Dense(units = 75, activation = leakyrelu),\n",
    "        #keras.layers.Dropout(rate=0.2),\n",
    "        tf.keras.layers.Dense(units = 53, activation = leakyrelu),\n",
    "        #keras.layers.Dropout(rate=0.2),\n",
    "\n",
    "        # final layer\n",
    "        tf.keras.layers.Dense(units = 22, activation = tf.nn.softmax),\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                  loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# Data processing\n",
    "input_shape, distances, labels = load_data()\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    distances, labels, test_size=0.2, shuffle = True, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# Create checkppoints\n",
    "\n",
    "checkpoint_path = \"checkpoints/checkpoint.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, save_weights_only=True, verbose=1,\n",
    "    # save weights, every 5-epoch\n",
    "    period=5)\n",
    "\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "# create a model instance\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "if latest: model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2120/2120 [==============================] - 0s 183us/sample - loss: 0.0929 - acc: 0.9689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x128bd7be0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "model.fit(x_train, y_train,callbacks = [cp_callback], epochs = 1) # save checkpoints at the end of each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-23-d9dcc78e42b9>:28: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.convert_variables_to_constants\n",
      "WARNING:tensorflow:From /Users/Nicolas/Programmation/Inter-plateformes/MODALNeurones/venv/lib/python3.7/site-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.compat.v1.graph_util.extract_sub_graph\n",
      "INFO:tensorflow:Froze 85 variables.\n",
      "INFO:tensorflow:Converted 85 variables to const ops.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./single_input_model.pb'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving the model\n",
    "\n",
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    \"\"\"\n",
    "    Freezes the state of a session into a pruned computation graph.\n",
    "\n",
    "    Creates a new computation graph where variable nodes are replaced by\n",
    "    constants taking their current value in the session. The new graph will be\n",
    "    pruned so subgraphs that are not necessary to compute the requested\n",
    "    outputs are removed.\n",
    "    @param session The TensorFlow session to be frozen.\n",
    "    @param keep_var_names A list of variable names that should not be frozen,\n",
    "                          or None to freeze all the variables in the graph.\n",
    "    @param output_names Names of the relevant graph outputs.\n",
    "    @param clear_devices Remove the device directives from the graph for better portability.\n",
    "    @return The frozen graph definition.\n",
    "    \"\"\"\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = ''\n",
    "        frozen_graph = tf.graph_util.convert_variables_to_constants(\n",
    "            session, input_graph_def, output_names, freeze_var_names)\n",
    "        return frozen_graph\n",
    "\n",
    "    \n",
    "frozen_graph = freeze_session(tf.keras.backend.get_session(), output_names=[out.op.name for out in model.outputs])\n",
    "tf.train.write_graph(frozen_graph, './', 'single_input_model.pb', as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531/531 [==============================] - 0s 247us/step\n",
      "[[ 3.78681  7.10552 10.4359  ...  3.81986  6.62413  3.79397]\n",
      " [ 3.77235  7.05716 10.2457  ...  3.79955  7.03971  3.79758]\n",
      " [ 3.85262  7.44246  8.57222 ...  3.79685  5.32892  3.79353]\n",
      " ...\n",
      " [ 3.80673  6.76573 10.1454  ...  3.77637  6.56263  3.77654]\n",
      " [ 3.81168  6.17607  9.75549 ...  3.80904  5.39576  3.80871]\n",
      " [ 3.79908  6.36971 10.0598  ...  3.78432  6.93845  3.7861 ]] 0.8436911495616432\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "print(x_test, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.3969073e-01 6.7140195e-06 6.2557554e-04 ... 1.8102363e-04\n",
      "  6.8735884e-05 5.2358825e-02]\n",
      " [9.9583793e-01 1.4883305e-03 3.1931300e-08 ... 1.0190373e-08\n",
      "  1.4338251e-05 1.3657890e-05]\n",
      " [2.6435481e-07 4.2474437e-11 7.2808199e-09 ... 6.5229406e-12\n",
      "  2.4000888e-06 6.0425198e-09]\n",
      " ...\n",
      " [3.4980474e-15 4.0880919e-13 4.5192414e-03 ... 4.3407101e-05\n",
      "  2.1701706e-10 1.1670590e-09]\n",
      " [1.2702364e-07 9.9999452e-01 1.9789296e-27 ... 1.0001491e-26\n",
      "  3.9817233e-10 1.2133797e-18]\n",
      " [5.4997608e-06 4.6032314e-06 2.4186775e-10 ... 6.9361796e-09\n",
      "  9.9953015e-09 1.6927938e-11]] [9.9583793e-01 1.4883305e-03 3.1931300e-08 7.7083848e-07 6.0922861e-10\n",
      " 2.1184855e-03 2.5168242e-06 6.3595849e-05 4.4813729e-04 5.3293110e-08\n",
      " 5.8160530e-09 9.3065555e-06 2.9085532e-12 8.1820787e-08 2.4497677e-07\n",
      " 5.7204244e-17 8.9311928e-17 2.7664664e-06 1.7836626e-08 1.0190373e-08\n",
      " 1.4338251e-05 1.3657890e-05]\n"
     ]
    }
   ],
   "source": [
    "Y = model.predict(x_test)\n",
    "print(Y, Y[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_index(A):\n",
    "    index = 0\n",
    "    a = A[0]\n",
    "    for i in range(len(A)):\n",
    "        if (A[i] > a):\n",
    "            index = i\n",
    "            a = A[i]\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = []\n",
    "for i in range(len(Y)):\n",
    "    Y1.append(max_index(Y[i, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 6, 2, 7, 5, 17, 7, 20, 19, 21, 5, 20, 1, 3, 1, 18, 6, 10, 1, 2, 18, 11, 0, 9, 7, 18, 19, 20, 0, 7, 21, 19, 6, 1, 0, 12, 7, 21, 0, 7, 6, 17, 0, 11, 18, 20, 19, 0, 17, 7, 7, 21, 0, 11, 0, 7, 19, 17, 2, 9, 7, 0, 21, 0, 2, 13, 5, 7, 0, 9, 0, 18, 6, 2, 7, 17, 7, 2, 7, 11, 11, 20, 9, 0, 10, 6, 1, 17, 7, 9, 17, 21, 12, 17, 12, 0, 21, 2, 2, 1, 6, 7, 17, 3, 13, 0, 1, 21, 2, 21, 2, 10, 0, 10, 13, 13, 7, 7, 7, 7, 19, 3, 10, 0, 12, 18, 0, 9, 3, 13, 6, 5, 17, 2, 7, 20, 2, 6, 7, 3, 3, 0, 12, 18, 11, 21, 2, 6, 17, 7, 21, 11, 5, 21, 12, 21, 2, 9, 0, 6, 21, 0, 11, 17, 7, 7, 7, 20, 7, 2, 7, 8, 20, 5, 5, 21, 17, 20, 1, 7, 2, 17, 7, 21, 17, 3, 5, 19, 21, 18, 10, 17, 1, 18, 2, 7, 21, 17, 3, 14, 2, 2, 9, 1, 3, 11, 19, 21, 9, 6, 2, 2, 9, 9, 20, 6, 1, 3, 11, 18, 17, 7, 5, 17, 9, 10, 5, 7, 3, 17, 6, 5, 18, 6, 10, 11, 17, 13, 7, 2, 17, 5, 18, 9, 21, 14, 6, 12, 3, 7, 2, 9, 1, 3, 18, 20, 9, 13, 3, 14, 13, 0, 20, 13, 3, 1, 2, 21, 21, 17, 18, 17, 5, 7, 13, 2, 18, 1, 17, 1, 7, 3, 9, 3, 5, 7, 0, 10, 0, 18, 0, 11, 6, 10, 7, 6, 18, 3, 17, 12, 2, 11, 7, 10, 7, 1, 2, 4, 2, 7, 3, 2, 10, 7, 3, 14, 0, 7, 5, 18, 7, 0, 12, 20, 7, 0, 2, 7, 10, 2, 11, 13, 18, 13, 19, 1, 7, 11, 3, 10, 3, 3, 7, 7, 17, 17, 21, 18, 1, 11, 2, 20, 21, 5, 20, 7, 2, 20, 9, 12, 5, 6, 18, 1, 7, 18, 7, 18, 18, 2, 19, 9, 9, 0, 3, 6, 5, 6, 6, 17, 17, 20, 3, 19, 4, 3, 20, 6, 2, 2, 11, 2, 12, 19, 0, 3, 19, 1, 1, 5, 11, 14, 6, 12, 3, 17, 17, 3, 9, 10, 17, 13, 7, 1, 2, 1, 7, 6, 3, 11, 9, 11, 18, 0, 4, 13, 3, 9, 18, 21, 17, 18, 2, 6, 11, 2, 18, 13, 6, 20, 0, 21, 20, 9, 13, 17, 20, 13, 0, 3, 1, 2, 0, 10, 6, 0, 21, 19, 20, 2, 0, 12, 5, 3, 0, 18, 0, 2, 20, 18, 5, 17, 10, 7, 19, 0, 2, 7, 7, 10, 12, 5, 7, 7, 1, 6, 21, 7, 5, 19, 7, 20, 6, 21, 5, 2, 11, 1, 20, 9, 21, 0, 3, 17, 10, 7, 18, 2, 13, 1, 0, 0, 18, 1, 13, 19, 6, 6, 8, 13, 7, 7, 1, 0, 5, 17, 18, 7, 1, 7] [ 0.  0.  7.  2.  7.  5.  3.  0. 20. 19. 21.  5. 20.  1.  3.  1. 18.  6.\n",
      " 10.  1.  2. 18. 11.  0.  0.  7. 18. 19. 20.  3.  7. 21. 19.  6.  1.  0.\n",
      " 10.  7. 21.  0.  7.  6. 17.  0. 11. 18.  3. 19.  0. 21.  7.  7.  0.  2.\n",
      " 11.  0.  7. 17. 17.  2.  9.  9.  0. 21.  7.  2. 13.  5.  7.  0.  0.  0.\n",
      " 18.  6.  2.  7. 17.  7.  2.  7. 11. 11. 20.  9.  0. 10.  7. 19.  3.  7.\n",
      "  9.  3. 21. 12. 17. 12.  0. 11.  2. 13.  1.  6.  7. 20.  3. 13.  0.  1.\n",
      " 21.  2.  0.  2. 10.  0. 21. 13. 10. 18.  7.  7.  7. 19.  3. 10.  0. 12.\n",
      " 18. 13.  9.  3. 13.  6.  5. 17.  2.  7. 20.  2.  6.  7.  3.  3.  0. 12.\n",
      " 11. 11. 21.  2.  6.  4.  7. 21. 17.  3. 18. 12. 20.  2.  9. 11.  6. 21.\n",
      "  0. 11. 17.  7.  7.  7. 20.  7. 12.  7.  8. 20.  5.  5. 21. 17. 20.  1.\n",
      "  7.  2. 17.  7. 21. 17.  3.  5. 19. 21. 17. 18. 17.  1. 18.  2.  7. 21.\n",
      " 17.  3. 14. 17. 12.  9.  2.  3. 11. 19. 21.  9.  6.  2.  2. 20.  9. 20.\n",
      "  6. 19.  3. 11. 18. 17. 20. 14. 17.  9. 10. 14.  7.  3. 17.  6.  5. 18.\n",
      "  6. 10. 11.  9. 13.  7.  2. 17. 14. 18.  9. 21.  0.  6. 12.  3. 17.  1.\n",
      "  9.  1.  3. 18. 18.  7. 13.  3. 14. 10.  0. 20. 13.  3.  1.  2. 21. 21.\n",
      " 17. 18. 17.  5.  7. 13.  2. 18.  1. 17. 21.  7.  3.  9.  3.  5. 11.  0.\n",
      " 10.  4. 18.  0. 11.  6. 10.  7.  6. 18.  3. 17. 12.  2. 11.  7. 10.  7.\n",
      "  1.  2.  0.  2.  7.  3.  2. 10.  7.  3. 14.  0.  7.  5. 18. 18.  0. 12.\n",
      " 20.  7.  0.  2.  7. 10.  2. 11. 13.  3. 13. 19.  1.  7. 11.  3. 10.  3.\n",
      "  3.  7.  7.  8. 17. 11.  0.  1. 11.  2. 20. 21.  5. 20.  7.  2. 20.  9.\n",
      " 12.  5.  6. 18.  3.  7. 18.  7. 18. 18.  2. 19.  9.  9.  0.  3.  6. 10.\n",
      "  6.  6.  8.  3. 20.  3. 19.  4.  3. 20.  6.  2. 10. 11.  2. 12. 19.  0.\n",
      "  3. 19.  5.  1.  5. 11. 14.  6. 12.  3. 17.  8.  3.  9.  4. 17. 13.  7.\n",
      "  1.  2.  1.  7.  6.  3. 11.  9. 11. 18.  0.  0. 13.  3.  9. 18. 18. 13.\n",
      " 18.  2.  6. 11. 17. 18. 13.  6. 20.  0. 21. 20.  7. 13. 17. 20. 13.  0.\n",
      "  3.  1.  2.  0. 13.  6. 11. 11. 19. 18.  2.  6. 12.  5.  3.  0. 18.  0.\n",
      "  2. 20. 18.  5. 17. 10.  7. 19.  0. 13. 20.  7. 10. 12.  5.  7.  7.  3.\n",
      "  6. 21.  7.  5. 19.  7. 20.  6. 21.  5.  2. 11.  1. 20.  9. 21.  0.  3.\n",
      " 17. 10.  7. 18.  2. 13.  1.  0.  0. 18.  1. 13. 19.  6.  6.  8. 13.  7.\n",
      "  7.  1.  0. 14. 17. 18.  7.  1.  7.] [  0.   0.  -1.   0.   0.   0.  14.   7.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   9.   0.   0.   0.\n",
      "   0.  -3.   0.   0.   0.   0.   0.   0.   2.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.  17.   0.   0.  -4.   0.   0.  21.  -2.   0.   0.\n",
      "   0.   2.   0.   0.   0.  -2.   0.   0.  -7.   0.   0.   0.   0.   0.\n",
      "   9.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.  -1. -18.  14.   0.   0.  14.   0.   0.   0.   0.   0.  10.\n",
      "   0. -11.   0.   0.   0.  -3.   0.   0.   0.   0.   0.   0.  21.   0.\n",
      "   0.   0. -11.   0.   3. -11.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0. -13.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   7.   0.   0.   0.   0.  13.   0.   0.  -6.   2.\n",
      "   3.   0.   1.   0.   0. -11.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   1.  -8.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0. -15. -10.   0.  -1.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0. -11.   0.   0.   0. -18.   0.   0.   0.   0. -13.  -9.\n",
      "   0.   0.   0.  -9.   0.   0.   0.   0.   0.   0.   0.   0.   0.   8.\n",
      "   0.   0.   0.   0.  -9.   0.   0.   0.  14.   0.   0.   0. -10.   1.\n",
      "   0.   0.   0.   0.   2.   2.   0.   0.   0.   3.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      " -20.   0.   0.   0.   0.   0.  -4.   0.   0.  -4.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   4.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0. -11.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  15.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   9.   0.  10.  18.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  -2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  -5.\n",
      "   0.   0.   9.  14.   0.   0.   0.   0.   0.   0.   0.   0.  -8.   0.\n",
      "   0.   0.   0.   0.   0.   0.  -4.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   9.   0.   0.   6.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   4.   0.   0.   0.   0.   3.   4.   0.   0.\n",
      "   0.   0. -15.   0.   0.   0.   0.   0.   0.   0.   2.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.  -3.   0. -11.  10.   0.   2.   0.  -6.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0. -11. -13.   0.   0.   0.   0.   0.   0.  -2.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.  -9.   0.   0.   0.   0.   0.]\n"
     ]
    }
   ],
   "source": [
    "print(Y1, y_test, Y1-y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
